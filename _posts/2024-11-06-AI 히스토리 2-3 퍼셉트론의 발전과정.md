---
layout: single
title: "AI 히스토리 2/3: 퍼셉트론의 발전과정, 2024 노벨 물리학상 해설 2부"
categories: dataScience
author_profile: false
sidebar:
  nav: "counts"
tags: [AI히스토리, 퍼셉트론, 2024 노벨 물리학상, 해설2부, 안될과학, 남세동, dataScience, AI]
---

### 안될과학: 퍼셉트론의 발전과정 2024 노벨 물리학상 해설 2부

{% include video id="A7PbaeuVhNA" provider="youtube" %}

### ChatGPT 영상 요약

* 여기 요약된 주요 내용입니다:

 1. AI에서 감정처럼 보이는 뉴런의 등장: AI 시스템은 감정을 학습한 적이 없음에도 불구하고 감정과 유사한 뉴런 활성화를 보여줍니다. 예를 들어, AI가 맥락에 따라 감정적으로 적절한 단어를 선택하는 모습을 보입니다.

2. 예쁜 꼬마 선충(C. elegans) 연구의 영향: 뉴런 302개의 간단한 신경 맵이 연구되어 AI 연구에 큰 영향을 주었습니다. 이를 통해 생물학적 신경 맵을 기반으로 한 인공신경망 모델이 가능해졌습니다.

3. 퍼셉트론의 한계: 단층 퍼셉트론은 XOR 문제와 같은 특정 논리 문제를 해결할 수 없다는 것이 수학적으로 증명되었습니다. 이 한계로 인해 다층 퍼셉트론의 필요성이 강조되었고, 이는 딥러닝의 시작이 되었습니다.

4. 다층 퍼셉트론(MLP)의 발전: 다층 퍼셉트론은 복잡하고 비선형적인 기능을 학습할 수 있게 하여, AI 시스템이 더 정교한 작업을 수행할 수 있게 했습니다.

5. AI 겨울과 부활: 다층 신경망 학습의 어려움으로 인해 한때 AI 연구가 정체되는 'AI 겨울'이 있었으나, 이후 알고리즘 및 컴퓨팅 파워의 발전으로 AI가 다시 급성장하게 되었습니다.

6. 뉴럴 네트워크의 필드 이론 적용: 필드 이론의 개념을 도입하여 신경망 내에서 뉴런 간 상호작용을 모델링할 수 있었습니다. 전자의 스핀 상태 등을 활용하여 복잡한 신경망 상호작용을 시뮬레이션하는 방식입니다.

7. 인간의 패턴 인식과 AI: 인간이 모호한 정보를 보고 패턴을 인식하는 것처럼, AI도 복잡한 데이터에서 패턴을 찾으려 노력합니다. 이는 AI가 이해 또는 예측을 위해 기본적으로 활용하는 방식입니다.

8. 노벨상 수상 기여: 신경과학 및 기계학습의 발전은 2024년 노벨 물리학상 수상 업적으로 이어졌으며, 이는 인간에 가까운 AI 시스템 개발에 큰 의미를 갖습니다.

9. 신경망 설계의 확장성 문제: 초창기에는 작은 신경망의 설계를 사람이 수동으로 할 수 있었으나, 수십억 개의 뉴런을 가진 현대 AI 시스템에서는 확장성이 큰 도전 과제로 남아 있습니다.

10. 패턴 기반 인지의 중요성: 인간의 뇌는 패턴 인식을 통해 정보를 간단히 처리하는데 능숙합니다. AI 모델도 이와 유사하게 많은 양의 데이터를 분석하고 이해하는 데 패턴 인식 방식을 활용합니다.

이 요약은 감정 뉴런과 관련된 AI의 발전, 생물학적 영감을 얻은 신경망 모델, 퍼셉트론의 역사적 한계 및 발전 과정을 다룹니다.

### 영상 후기: 다층 퍼셉트론으로 발전
* 단층 퍼셉트론의 한계(XOR 게이트 기능 불가능)를 극복한 다층 퍼셉트론
* 그러나 다층 퍼셉트론에서 w 계산 문제로 찾아온 AI 발전의 겨울.
* 그 겨울을 끝내고 봄이 오게한 홉필드 네트웤.
* 홉필드 네트워크를 통해서, 인간 생존본능에 새겨진 패턴인식과 기억의 방식을 기계학습에도 적용이 가능해짐.
* 보이는 것만이 전부가 아님. 보이는 것(v)과 보이지 않고 감춰진 것(h)을 적용한 힌튼의 볼츠만 순환머신, 한번 더 발전한 비순환 볼츠만 머신. 사실 그게 딥러닝과 같음.
* 학습을 통해서 w값을 계산할 수 있게됨. 시키지도 않았는데 배경의 감정까지 식별하게 됨.
* 단층 퍼셉트론은 평면 상에서 직선 경계선을 찾는 방법이라면, 다층 퍼셉트론은 입체 공간 상에서 여러 곡선 경계선을 찾는 방법임. 그게 커브피팅과 같음.
* 색상 선호도가 반영된 소량의 학습 데이터로 맞춤형 경계선 w값 곡선을 계산할 수 있게됨.
* 커브피팅은 손실이 감소하는 쪽으로 예측을 반복하는 것임.


### [나무위키: 제프리 힌튼](https://namu.wiki/w/%EC%A0%9C%ED%94%84%EB%A6%AC%20%ED%9E%8C%ED%8A%BC){: target="_blank"}

### [나무위키: 존 홉필드](https://namu.wiki/w/%EC%A1%B4%20%ED%99%89%ED%95%84%EB%93%9C){: target="_blank"}