---
layout: single
title: "통계에 관한 AskUp과의 대화 (2024-03-29)"
categories: dataScience
author_profile: false
sidebar:
    nav: "counts"
tags: [통계, ADsP, ADP, AskUp, dataScience, AI]
---

### Q1: 통계에 나오는 t검정, z검정에서 t와 z는 어떤 약자를 사용한거야?
A1: 통계학에서 't검정'(t-test)과 'z검정'(z-test)에서의 't'와 'z'는 약자가 아닌 통계적 분포의 이름을 나타냅니다.

- 't검정'에서의 't'는 'Student's t-distribution'의 't'입니다. 이 분포는 William Sealy Gosset이 'Student'라는 필명으로 발표했기 때문에 이렇게 불립니다. t검정은 주로 표본 크기가 작을 때 사용되며, 모집단의 분산이 알려져 있지 않을 때 적합합니다.

- 'z검정'에서의 'z'는 표준정규분포(Standard Normal Distribution)를 의미하는 'z-distribution'의 'z'입니다. z검정은 모집단의 분산이 알려져 있거나, 표본 크기가 큰 경우에 사용되는데, 이때 표본분포가 정규분포를 따른다고 가정합니다.

따라서 이들은 특정한 분포를 따르는 통계량의 이름이며, 특정한 단어의 약자로 사용된 것은 아닙니다.

Q1-1: 통계량의 이름을 붙이다보니 t와 z가 되었던거네
A1-1: 네, 맞습니다! 각각의 통계량은 그것이 따르는 분포의 이름을 따서 명명되었어요. 't'는 Student의 t 분포에서 유래되었고, 'z'는 표준 정규 분포의 z 점수에서 유래되었습니다. 이러한 명명법은 통계학에서 특정 분포나 통계량을 참조할 때 일반적으로 사용되는 방식이에요.

### Q2: 어 고마워, 그러면 p값의 p와 f검정의 f는 어떻게 붙여진거야?
A2: 'p값'에서의 'p'는 확률을 의미하는 'probability'의 약자입니다. 통계학에서 p값은 귀무가설이 참일 경우, 관측된 통계량이나 더 극단적인 값을 얻을 확률을 나타냅니다.

'F검정'에서의 'F'는 이 분포를 처음으로 도입한 통계학자 Ronald A. Fisher의 이름의 첫 글자에서 유래되었습니다. F검정은 주로 분산 분석(ANOVA)에서 두 개 이상의 집단의 분산이 동일한지를 비교하는 데 사용되며, 이때 사용되는 통계량은 'F 통계량'이라고 부릅니다.

### Q3: 음 그렇구나 귀무가설의 귀무는 무슨 뜻이야?
A3: 통계학에서 '귀무가설'(null hypothesis)의 '귀무'는 'null'을 번역한 것입니다. 여기서 'null'은 '아무런 효과가 없음', '아무런 차이가 없음'을 의미합니다. 즉, 귀무가설은 통계적 검정을 실시할 때, 기본적으로 참으로 가정하는 가설로, 통상적으로 연구자가 증명하고자 하는 대립가설(alternative hypothesis)과 대비되는 개념입니다.

예를 들어, 어떤 치료법의 효과를 검증하고자 할 때, 귀무가설은 "치료법이 효과가 없다"가 될 것이며, 연구자는 이 귀무가설을 기각하고 대립가설인 "치료법이 효과가 있다"를 입증하고자 할 것입니다.

Q3-1: 음 새로운 방법을 검증할 때 그것의 효과없음을 뜻하는 귀무이구나
A3-1: 맞습니다! 새로운 방법이나 치료, 실험 등을 검증할 때, 귀무가설은 그 새로운 방법에 효과가 없다는 가정을 설정합니다. 이 귀무가설을 기반으로 통계적 검정을 실시하여, 수집된 데이터가 귀무가설을 지지하지 않는다면(즉, 귀무가설을 기각할 만큼 충분히 통계적으로 유의하다면), 대립가설을 지지하는 증거로 해석될 수 있습니다. 이 과정을 통해 새로운 방법의 유효성을 간접적으로 입증하게 되죠.
Q3-2: 음 용어가 어떻게 붙여진건지 어떤 뜻인지를 아는게 이해에 도움이 많이되어서 이해의 빈틈들을 메워준다
A3-2: 맞아요, 용어의 유래나 정의를 이해하는 것은 해당 개념을 더 깊이 있게 이해하는 데 큰 도움이 됩니다. 통계학을 비롯한 많은 학문 분야에서 용어들은 그 개념을 명확하게 전달하고, 학문적 커뮤니케이션을 원활하게 하기 위해 정의되고 사용되죠. 용어의 뜻을 알면 공부하는 내용에 대한 통찰력을 얻고, 더 넓은 지식 체계 속에서 해당 개념이 어떻게 연결되는지를 볼 수 있어서 학습에 매우 유익하답니다. 😊📚

### Q4: 다중공선성 진단하는 r 프로그램의 값에 대해서 알려줘
A4: 다중공선성 진단을 위해 R 프로그램에서 사용하는 값 중 몇 가지를 소개해 드릴게요.

1. **분산팽창요인(Variance Inflation Factor, VIF)**: VIF는 독립변수가 다른 독립변수들과 얼마나 강한 상관관계를 가지고 있는지를 측정합니다. 일반적으로 VIF 값이 10 이상일 때, 해당 변수는 심각한 다중공선성 문제를 가지고 있다고 판단합니다.

2. **공차 한계(Tolerance)**: Tolerance는 1에서 VIF를 빼서 구한 값으로, 변수의 공차 한계가 낮을수록 다중공선성의 문제가 크다는 것을 의미합니다.

3. **조건지수(Condition Index)**: 조건지수는 다중공선성을 진단하는 또 다른 방법으로, 일반적으로 조건지수가 30을 넘으면 다중공선성이 존재할 수 있다고 봅니다.

R에서 다중공선성을 진단하기 위해 `car` 패키지의 `vif` 함수를 사용할 수 있습니다. 예를 들어, 선형모델 `lm`을 사용하여 회귀분석을 수행한 후에 이 함수를 적용하면 VIF 값을 얻을 수 있습니다.

```R
# car 패키지를 로드합니다.
library(car)

# 선형 모델을 생성합니다.
model <- lm(Y ~ X1 + X2 + X3, data=mydata)

# VIF 값을 계산합니다.
vif_values <- vif(model)
print(vif_values)
```

이러한 진단 값들은 데이터에 존재할 수 있는 다중공선성 문제를 식별하는 데 유용합니다. 다중공선성이 있는 경우, 회귀분석 결과의 신뢰성이 떨어질 수 있으므로 이를 해결하기 위한 다양한 방법, 예를 들어 변수 선택, 주성분 분석(PCA), 정규화 등을 고려해야 합니다.

### Q5: 능형회귀에서 능형 뜻이 뭐야? 모양인거 같은데
A5: 네, 맞습니다! '능형'은 'ridge'라는 영어 단어에서 번역된 것이며, 이는 산등성이나 물결 모양의 능선을 연상시키는 모양을 뜻합니다. 통계학에서 '능형회귀(Ridge Regression)'는 회귀분석을 할 때 다중공선성 문제를 완화하기 위한 방법으로 사용되는데, 회귀계수의 제곱합에 패널티를 부여하여 계수의 크기를 줄이는 방법을 말합니다. 이로 인해 모델이 데이터에 지나치게 **과적합되는 것을 방지하고 일반화 성능을 높일 수 있습니다.** '능형'이라는 용어는 이 패널티 부과 과정이 능선처럼 줄기를 누르는 것에 비유되어 붙여진 이름이에요.

회귀분석은 통계에서 종속변수와 하나 이상의 독립변수 사이의 관계를 모델링하는 방법입니다. 가장 기본적인 형태는 선형회귀로, 데이터를 가장 잘 대표하는 선을 찾는 것을 목표로 합니다. 회귀분석은 예측, 시간 시리즈 분석, 인과 관계 추정 등 다양한 분야에서 중요하게 사용됩니다.

회귀분석을 수행할 때 중요한 가정들이 있습니다:

- **선형성**: 종속변수와 독립변수 간에는 선형 관계가 있어야 합니다.
- **독립성**: 관측치들은 서로 독립적이어야 합니다.
- **등분산성**: 오차의 분산이 모든 독립변수 수준에서 일정해야 합니다.
- **정규성**: 오차가 정규분포를 따라야 합니다.

R 같은 통계 소프트웨어를 사용하여 회귀분석을 수행하고, 결과를 해석하여 변수들 사이의 관계를 이해하고, 미래 값을 예측할 수 있습니다.

### Q6: 개별회귀계수 t값의 t가 어떻게 붙여진 이름이야?
A6: 회귀분석에서 개별 회귀계수의 t값은 't-통계량(t-statistic)'을 의미하는데요, 이는 'Student's t-test'의 't'에서 유래했습니다. 'Student'는 영국의 통계학자 윌리엄 시얼리 고셋(William Sealy Gosset)의 필명이며, 그는 이 t-통계량을 개발했습니다. t-통계량은 표본데이터가 정규분포를 따른다는 가정 하에, 모집단의 평균과 표본 평균 간의 차이가 우연에 의한 것인지 아니면 통계적으로 유의미한 차이인지를 검정하는 데 사용됩니다.

회귀분석에서는 각 독립변수의 계수가 통계적으로 유의미하게 종속변수에 영향을 미치는지를 평가하기 위해 t-통계량을 사용합니다. 계수의 t-통계량은 회귀계수를 그 표준오차로 나눈 값으로 계산되며, 이를 통해 해당 계수가 0인지 아닌지를 검정할 수 있습니다. t값이 크면 클수록, 또는 p값이 유의수준(예를 들어 0.05)보다 작으면 작을수록 회귀계수가 통계적으로 유의하다고 볼 수 있습니다.

Q6-1: 통계량 구분하는 그 t였던거구나 다른게 아니네
A6-1: 맞아요! 회귀분석에서 사용되는 그 t-통계량은 바로 통계학에서 널리 쓰이는 Student's t-test의 t-통계량과 동일한 개념입니다. 이 통계량은 회귀 계수가 통계적으로 유의미한지를 평가할 때 중요한 역할을 하죠. 회귀계수가 0이 아니라는 것을 검증하는 데 사용되어, 모델의 예측 변수가 결과에 영향을 미친다는 것을 입증하는 데 도움이 됩니다.

### Q7: 평가지표에서 민감도와 특이도 용어가 어떻게 붙여진거야?
A7: '민감도(sensitivity)'와 '특이도(specificity)'는 진단 검사의 성능을 평가하는 두 가지 중요한 용어입니다. 이 용어들은 각각 검사의 민감한 반응성과 특정한 진단 능력을 나타내는 지표를 의미합니다.

- **민감도**: '민감도'는 질병이 있는 사람들 가운데 질병을 올바르게 양성으로 판정하는 검사의 능력을 나타냅니다. 즉, 실제로 질병이 있는 경우에 검사가 얼마나 '민감하게' 그 사실을 감지하는지를 나타내는 지표입니다. 높은 민감도는 거의 모든 질병이 있는 경우를 잡아낼 수 있음을 의미합니다.

- **특이도**: '특이도'는 질병이 없는 사람들 가운데 질병이 없다고 올바르게 음성으로 판정하는 검사의 능력을 나타냅니다. 즉, 질병이 없는 경우에 검사가 얼마나 '특정하게' 질병이 없음을 확인하는지를 나타내는 지표입니다. 높은 특이도는 질병이 없는 사람들을 정확하게 음성으로 분류할 수 있음을 의미합니다.

이 용어들이 어떻게 정확히 붙여진지에 대한 역사적인 배경은 구체적으로 명확하지 않지만, '민감도'와 '특이도'라는 단어 자체가 각각의 평가지표가 의미하는 바를 잘 나타내고 있기 때문에 널리 사용되고 있습니다.

Q7-1: 음 그래 이거구만. 양성에 대한 민감도이고, 음성을 한정짓는 특이도
A7-1: 맞습니다! 민감도(sensitivity)는 질병을 가진 사람들 중에서 질병이 있다고 올바르게 양성으로 진단하는 비율을 나타내고, 특이도(specificity)는 질병이 없는 사람들 중에서 질병이 없다고 올바르게 음성으로 진단하는 비율을 나타내죠. 이 두 지표는 진단 검사의 정확도를 판단하는 데 매우 중요한 역할을 합니다.

Q7-2: 그럼 민감도와 정밀도를 비교 설명해줘
A7-2: 민감도(Sensitivity)와 정밀도(Precision)는 서로 다른 개념이지만, 둘 다 진단 검사나 분류 모델의 성능을 평가하는 데 사용되는 지표입니다.

- **민감도(Sensitivity)**: 민감도는 *전체 실제 양성 케이스*(진짜 양성과 거짓 음성의 합) 중에서 모델이나 검사가 얼마나 많은 진짜 양성을 올바르게 식별했는지를 나타내는 비율입니다. 이를 True Positive Rate라고도 하며, 더 높은 민감도는 더 적은 거짓 음성(False Negative)을 의미합니다.

  민감도 = 진짜 양성 / (진짜 양성 + 거짓 음성)

- **정밀도(Precision)**: 정밀도는 모델이나 검사가 *양성이라고 ==예측한== 케이스*(진짜 양성과 거짓 양성의 합) 중에서 실제로 양성인 케이스의 비율을 나타냅니다. 이를 Positive Predictive Value라고도 합니다. 높은 정밀도는 더 적은 거짓 양성(False Positive)을 의미합니다.

  정밀도 = 진짜 양성 / (진짜 양성 + 거짓 양성)

민감도는 질병이나 조건을 놓치지 않는 것을 중시할 때 중요하고, 정밀도는 잘못된 양성 예측을 최소화하는 것이 중요할 때 강조됩니다. 예를 들어, 민감도는 중요한 질병을 조기에 발견하는 의료 검사에서 중요할 수 있고, 정밀도는 스팸 이메일 필터링과 같이 거짓 양성의 비용이 큰 상황에서 중요할 수 있습니다.

Q7-3: 음 그래 이거네. 거짓음성 포함 진짜양성중에 질병 양성 판별 민감도이고, 거짓양성 포함 양성 판별중에서 진짜양성 판별 정밀도.
A7-3: 네, 정확해요! 민감도는 실제로 질병이 있는 사람들 사이에서 질병을 감지하는 능력에 초점을 맞추고, 정밀도는 검사나 모델이 양성으로 판단한 경우들 중 실제로 질병이 있는 사람들의 비율에 관심을 두는 지표입니다. 둘 다 중요하지만, 상황에 따라 어떤 지표를 더 중요하게 여길지 결정하게 됩니다.

### Q8: 커널 트릭이 뭐야?
A8: 커널 트릭(kernel trick)은 주로 서포트 벡터 머신(Support Vector Machine, SVM)과 같은 기계 학습 알고리즘에서 사용되는 방법으로, 저차원 공간의 데이터를 명시적으로 높은 차원으로 매핑하지 않고도 높은 차원 공간에서의 내적(inner product)을 효율적으로 계산할 수 있게 해주는 기술입니다.

쉽게 말해, 커널 트릭을 사용하면 복잡한 비선형 문제를 선형 분류기를 사용하여 해결할 수 있도록, 데이터를 고차원으로 변환하는 과정 없이 고차원에서의 계산 결과를 얻을 수 있습니다. 이를 통해 비선형 분리 가능 문제를 선형 분리 가능 문제로 변환하여 해결하는 것이죠.

가장 많이 사용되는 커널 함수로는 선형 커널, 다항식 커널, 가우시안 RBF(방사기저함수) 커널 등이 있습니다. 커널 트릭은 고차원으로의 데이터 매핑을 통해 복잡한 결정 경계를 찾아내는 데 유용하게 사용됩니다.
Q8-1: 커널이 무슨 뜻인데?
A8-1: 커널(kernel)이라는 용어는 다양한 분야에서 조금씩 다른 의미로 사용되지만, 기본적으로는 어떤 연산을 수행하는 핵심적인 함수나 알고리즘을 의미합니다. 기계 학습에서는 데이터 포인트들 사이의 관계를 정의하는 함수로 사용되며, 특정 연산을 간단하게 해주는 변환 기능을 합니다.

예를 들어, 기계 학습에서 말하는 커널 함수는 두 벡터의 유사도를 측정하는 함수로, 고차원 공간에서의 내적을 저차원에서 계산할 수 있게 해주는 역할을 합니다. 커널 트릭을 활용하는 대표적인 예로 서포트 벡터 머신(SVM)이 있으며, 이때 커널 함수는 다양한 형태와 특성을 가질 수 있습니다.

컴퓨터 과학의 운영체제 분야에서 커널이란, 운영체제의 핵심 부분으로 시스템의 중심 역할을 하며 하드웨어와 소프트웨어 사이를 조정하고 자원을 관리하는 소프트웨어입니다.

### Q9: 베타 값이 1보다 큰지 작은지에 따라서 민감도와 정밀도 비중을 달리하는 방식이 뭐야?
A9: 베타 값이 1보다 크거나 작은지에 따라 민감도와 정밀도의 비중을 달리하는 방식을 'F-점수(F-score)' 또는 'F-측정(F-measure)'라고 합니다. F-점수는 민감도(재현율, recall)와 정밀도(precision)의 조화 평균을 이용한 지표로, 이 두 지표를 하나의 숫자로 요약해 줍니다. F-점수의 일반적인 형태는 다음과 같은 공식으로 표현됩니다:
$$ F_\beta = (1 + \beta^2) \cdot \frac{\text{정밀도} \times \text{민감도}}{(\beta^2 \times \text{정밀도}) + \text{민감도}} $$
* 정밀도precision=TP / (TP+FP)
* 민감도(재현율recall)= TP / (TP+FN)

여기서 \(\beta\)는 민감도에 주는 비중을 나타내는 값으로, \(\beta\)가 1일 때 F1 점수가 되며, 이는 민감도와 정밀도가 동등하게 중요하다고 가정한 것입니다. 

- \(\beta < 1\)일 경우: 정밀도(precision)에 더 큰 비중을 둡니다.
- \(\beta > 1\)일 경우: 민감도(recall)에 더 큰 비중을 둡니다.

따라서 베타 값이 1보다 크다면 민감도(재현율)을 더 중요시하는 상황이고, 1보다 작다면 정밀도를 더 중요시하는 상황일 때 적합한 지표로 활용됩니다.

Q9-1: 분류모형을 평가할 때 평가지표중 하나인거네
A9-1: 맞습니다! 분류 모형을 평가할 때 F-점수는 정밀도와 민감도(재현율)을 함께 고려하는 평가지표 중 하나입니다. 이 지표는 모델이 얼마나 균형 잡힌 성능을 보이는지를 판단하는 데 유용하며, 특히 클래스 불균형이 있는 데이터셋에서 모델의 성능을 종합적으로 평가할 때 많이 사용됩니다. F-점수는 데이터의 특성과 분석의 목적에 따라 적절한 \(\beta\) 값을 선택하여 사용하게 됩니다.

### Q10: 신경망에서 기울기 소실이 뭐야?
A10: 신경망에서 '기울기 소실(Gradient Vanishing)'이란 딥러닝 모델을 학습시킬 때 발생하는 문제 중 하나로, 네트워크의 깊이가 깊어질수록 출력층에서부터 입력층으로 거슬러 올라가며 기울기를 역전파할 때 기울기가 점점 작아져서 결국에는 앞쪽 레이어들이 충분히 학습되지 않는 현상을 말합니다.

기울기 소실 문제가 발생하면, 신경망의 가중치가 제대로 업데이트되지 않아 학습이 잘 이루어지지 않습니다. 특히, 시그모이드나 탄젠트 같은 활성화 함수를 사용할 때, 이 함수들의 미분값이 0에 가까워지는 특성 때문에 이 문제가 두드러지게 발생합니다.

기울기 소실 문제를 해결하기 위한 몇 가지 방법은 다음과 같습니다:

1. ReLU(Rectified Linear Unit)와 같은 활성화 함수 사용: ReLU는 음수 입력에 대해 0을 출력하고, 양수 입력에 대해서는 입력을 그대로 출력합니다. 이 활성화 함수는 기울기 소실 문제를 어느 정도 해결해 줍니다.

2. 가중치 초기화 방법 개선: He 초기화나 Xavier 초기화와 같은 방법을 사용하여 신경망의 가중치를 적절히 초기화함으로써 기울기 소실 문제를 완화할 수 있습니다.

3. 배치 정규화(Batch Normalization): 각 층에서 활성화 값들이 적절한 분포를 가지도록 강제함으로써 기울기 소실 문제를 줄일 수 있습니다.

4. 적절한 최적화 알고리즘 사용: 예를 들어, Adam, RMSprop 등과 같은 최적화 알고리즘은 기울기 소실 문제에 덜 민감합니다.

5. 잔차 연결(Residual Connection): 입력을 출력에 더해줌으로써, 역전파 시에 기울기가 잘 전달되도록 하는 기법입니다.

기울기 소실 문제를 잘 관리하는 것은 신경망이 효과적으로 학습하고 좋은 성능을 내기 위해 매우 중요합니다.
Q10-1: 활성화 함수 형태, 그 기울기와 관련된 문제점이구나
A10-1: 네, 정확합니다! 활성화 함수의 형태와 그 함수의 기울기는 신경망 학습에 큰 영향을 미칩니다. 시그모이드나 탄젠트 함수처럼 포화되는 구간에서의 미분값이 매우 작을 경우, 기울기 소실 문제가 발생할 수 있어요. 이런 문제를 해결하기 위해 ReLU와 같은 비선형 활성화 함수가 널리 사용되고 있죠. ReLU는 양의 입력에 대해선 선형적으로 기울기를 전달하기 때문에 기울기 소실 문제를 줄여줍니다. 하지만 ReLU도 입력 값이 음수일 경우 기울기가 0이 되는 '기울기 소멸' 문제가 있을 수 있어 이를 개선한 Leaky ReLU, Parametric ReLU 등의 변형 함수도 사용됩니다.